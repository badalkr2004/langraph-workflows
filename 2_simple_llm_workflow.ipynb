{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2eb007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f61c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "298fc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a state\n",
    "class LLMState(TypedDict):\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41ee479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_qa(state: LLMState)->LLMState:\n",
    "\n",
    "    # extract the question\n",
    "    ques = state[\"question\"]\n",
    "\n",
    "    # form a prompt\n",
    "    prompt = f\"Answer the following question\\n{ques}\"\n",
    "\n",
    "    # ask the question form the llm model\n",
    "    ans = model.invoke(prompt).content\n",
    "\n",
    "    # update the state\n",
    "    state[\"answer\"] = str(ans)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9870c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph\n",
    "\n",
    "graph = StateGraph(LLMState)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node(\"llm_qa\",llm_qa)\n",
    "\n",
    "# add edges\n",
    "\n",
    "graph.add_edge(START,\"llm_qa\")\n",
    "graph.add_edge(\"llm_qa\",END)\n",
    "\n",
    "# compile the graph\n",
    "workflow = graph.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2765c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is langchain', 'answer': '**LangChain** is an open-source framework designed to simplify the development of applications powered by Large Language Models (LLMs).\\n\\nIn essence, while LLMs are incredibly powerful for generating text, answering questions, and performing various language tasks, they have limitations when it comes to real-world applications:\\n\\n1.  **Lack of Context:** They don\\'t inherently remember past conversations or have access to real-time, external data.\\n2.  **Limited Tool Use:** They can\\'t directly interact with external systems like databases, APIs, or web search engines.\\n3.  **Complex Workflows:** Building multi-step processes (e.g., \"look up info, summarize it, then draft an email\") with raw LLMs is challenging.\\n\\n**LangChain addresses these limitations by providing a structured way to:**\\n\\n1.  **Connect LLMs to Data Sources:** Allow LLMs to access and interact with your specific data (documents, databases, APIs) to provide more relevant and up-to-date information. This is often referred to as **Retrieval Augmented Generation (RAG)**.\\n2.  **Enable LLMs to Interact with Their Environment (Tools):** Give LLMs the ability to \"use tools\" (like a web search engine, a calculator, or a custom API call) to perform actions or gather information beyond their training data.\\n3.  **Orchestrate Complex Workflows (Chains & Agents):** Combine multiple LLM calls and other components into logical sequences or allow the LLM to intelligently decide which steps to take based on the user\\'s request.\\n\\n---\\n\\n**Key Concepts and Components of LangChain:**\\n\\n*   **Models:** Integrations with various LLM providers (OpenAI, Hugging Face, Anthropic, etc.) and different model types (chat models, text models, embeddings).\\n*   **Prompts:** Tools for creating, managing, and optimizing prompts for LLMs, including templating and output parsing.\\n*   **Chains:** Sequences of calls, where the output of one component (e.g., an LLM call) becomes the input for the next. This allows for multi-step reasoning.\\n*   **Retrievers:** Components that fetch relevant documents or data from external sources (e.g., vector databases, document loaders) to augment the LLM\\'s context.\\n*   **Memory:** Systems for persisting state between runs of a chain, allowing LLMs to remember past interactions in a conversation.\\n*   **Agents:** The most advanced concept. Agents use an LLM as a \"reasoning engine\" to decide which tools to use and in what order to achieve a specific goal. They can dynamically adapt their plan.\\n*   **Tools:** Functions or APIs that an agent can call to interact with the outside world (e.g., Google Search, a Python interpreter, custom database queries).\\n\\n---\\n\\n**What Can You Build with LangChain? (Use Cases):**\\n\\n*   **Advanced Chatbots:** Chatbots that can remember past conversations, answer questions based on your specific documents, and even perform actions (like booking a meeting).\\n*   **Question Answering over Documents:** Systems that can answer complex questions by searching through vast amounts of internal company documents, PDFs, or web content.\\n*   **Intelligent Agents:** LLMs that can autonomously perform tasks by deciding which tools to use (e.g., a research agent that uses web search, summarizes findings, and then writes a report).\\n*   **Data Extraction and Summarization:** Tools to extract specific information from unstructured text or summarize long articles.\\n*   **Content Generation:** More sophisticated content creation tools that can pull in external data to generate richer, more accurate output.\\n\\n---\\n\\n**In summary:**\\n\\nLangChain acts as an **orchestration layer** or a **toolkit** that elevates LLMs from powerful text generators into intelligent, context-aware, and action-oriented applications. It provides the building blocks and abstractions necessary to create sophisticated LLM-powered systems that can interact with real-world data and tools. It\\'s available in both Python and JavaScript/TypeScript.'}\n"
     ]
    }
   ],
   "source": [
    "inital_state: LLMState = {\"question\": \"What is langchain\", \"answer\": \"\"}\n",
    "final_state  = workflow.invoke(inital_state)\n",
    "print(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
